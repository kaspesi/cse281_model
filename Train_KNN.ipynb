{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing the Data\n",
    "Now that we have the raw data, let's process it. \n",
    "We'll first load the data into numpy arrays, and randomly split it into train and test with a 75/25 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import urllib\n",
    "import cv2\n",
    "import csv\n",
    "import ssl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "# get a handle on the bucket that holds your file\n",
    "bucket = s3.Bucket('sagemaker-hotels50k-train') # example: energy_market_procesing\n",
    "# get a handle on the object you want (i.e. your file)\n",
    "obj = bucket.Object(key='train/dataset.csv') # example: market/zone1/data.csv\n",
    "# get the object\n",
    "response = obj.get()\n",
    "# read the contents of the file\n",
    "lines = response['Body'].read()\n",
    "lines = lines.decode('utf-8')\n",
    "lines = lines.split()\n",
    "# now iterate over those lines\n",
    "iterator = 0\n",
    "labels = []\n",
    "pixelArray = []\n",
    "\n",
    "#To ignore SSL\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "print(\"Starting image download...\")\n",
    "for row in csv.reader(lines):\n",
    "    if iterator != 0:\n",
    "        resp = urllib.request.urlopen(row[2], context=ctx)\n",
    "        image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "        #print(image)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        #print(iterator)\n",
    "        pixels = cv2.resize(image, (32,32)).flatten()\n",
    "        labels.append(int(row[1]))\n",
    "        pixelArray.append(pixels)\n",
    "    iterator += 1\n",
    "print(labels)\n",
    "    \n",
    "(train_features, test_features, train_labels, test_labels) = train_test_split(pixelArray, labels, test_size=0.25, random_state=42)\n",
    "print(\"Finished setting train/test features/labels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Amazon S3\n",
    "Now, since typically the dataset will be large and located in Amazon S3, let's write the data to Amazon S3 in recordio-protobuf format. We first create an io buffer wrapping the data, next we upload it to Amazon S3. Notice that the choice of bucket and prefix should change for different users and different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features shape =  (375, 3072)\n",
      "train_labels shape =  (375,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels = train_labels.astype('int')\n",
    "train_features = train_features.astype('int')\n",
    "print('train_features shape = ', train_features.shape)\n",
    "print('train_labels shape = ', train_labels.shape)\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, train_features, train_labels)\n",
    "buf.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://sagemaker-hotels50k/testing/train/feature-vectors\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "bucket = 'sagemaker-hotels50k'\n",
    "prefix = 'testing'\n",
    "key = 'feature-vectors'\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to provide test data. This way we can get an evaluation of the performance of the model from the training logs. In order to use this capability let's upload the test data to Amazon S3 as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_features shape =  (125, 3072)\n",
      "test_labels shape =  (125,)\n",
      "uploaded test data location: s3://sagemaker-hotels50k/testing/test/feature-vectors\n"
     ]
    }
   ],
   "source": [
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = test_labels.astype('int')\n",
    "test_features = test_features.astype('int')\n",
    "\n",
    "print('test_features shape = ', test_features.shape)\n",
    "print('test_labels shape = ', test_labels.shape)\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, test_features, test_labels)\n",
    "buf.seek(0)\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test', key)).upload_fileobj(buf)\n",
    "s3_test_data = 's3://{}/{}/test/{}'.format(bucket, prefix, key)\n",
    "print('uploaded test data location: {}'.format(s3_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We take a moment to explain at a high level, how Machine Learning training and prediction works in Amazon SageMaker. First, we need to train a model. This is a process that given a labeled dataset and hyper-parameters guiding the training process,  outputs a model. Once the training is done, we set up what is called an **endpoint**. An endpoint is a web service that given a request containing an unlabeled data point, or mini-batch of data points, returns a prediction(s).\n",
    "\n",
    "In Amazon SageMaker the training is done via an object called an **estimator**. When setting up the estimator we specify the location (in Amazon S3) of the training data, the path (again in Amazon S3) to the output directory where the model will be serialized, generic hyper-parameters such as the machine type to use during the training process, and kNN-specific hyper-parameters such as the index type, etc. Once the estimator is initialized, we can call its **fit** method in order to do the actual training.\n",
    "\n",
    "Now that we are ready for training, we start with a convenience function that starts a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "\n",
    "def trained_estimator_from_hyperparams(s3_train_data, hyperparams, output_path, s3_test_data=None):\n",
    "    \"\"\"\n",
    "    Create an Estimator from the given hyperparams, fit to training data, \n",
    "    and return a deployed predictor\n",
    "    \n",
    "    \"\"\"\n",
    "    # set up the estimator\n",
    "    knn = sagemaker.estimator.Estimator(get_image_uri(boto3.Session().region_name, \"knn\"),\n",
    "        get_execution_role(),\n",
    "        train_instance_count=1,\n",
    "        train_instance_type='ml.m5.2xlarge',\n",
    "        output_path=output_path,\n",
    "        sagemaker_session=sagemaker.Session())\n",
    "    knn.set_hyperparameters(**hyperparams)\n",
    "    \n",
    "    # train a model. fit_input contains the locations of the train and test data\n",
    "    fit_input = {'train': s3_train_data}\n",
    "    if s3_test_data is not None:\n",
    "        fit_input['test'] = s3_test_data\n",
    "    knn.fit(fit_input)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run the actual training job. For now, we stick to default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-02 22:37:09 Starting - Starting the training job...\n",
      "2020-12-02 22:37:11 Starting - Launching requested ML instances......\n",
      "2020-12-02 22:38:33 Starting - Preparing the instances for training...\n",
      "2020-12-02 22:39:04 Downloading - Downloading input data...\n",
      "2020-12-02 22:39:10 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 INFO 140716057478976] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'index_metric': u'L2', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'_log_level': u'info', u'feature_dim': u'auto', u'faiss_index_ivf_nlists': u'auto', u'epochs': u'1', u'index_type': u'faiss.Flat', u'_faiss_index_nprobe': u'5', u'_kvstore': u'dist_async', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000'}\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 INFO 140716057478976] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'sample_size': u'200', u'feature_dim': u'3072', u'predictor_type': u'classifier', u'k': u'10'}\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 INFO 140716057478976] Final configuration: {u'index_metric': u'L2', u'predictor_type': u'classifier', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'_log_level': u'info', u'feature_dim': u'3072', u'faiss_index_ivf_nlists': u'auto', u'sample_size': u'200', u'epochs': u'1', u'index_type': u'faiss.Flat', u'_faiss_index_nprobe': u'5', u'_kvstore': u'dist_async', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'k': u'10'}\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 WARNING 140716057478976] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 INFO 140716057478976] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 INFO 140716057478976] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/73a6b0b1-d370-47e6-bda0-aa7d19c643b4', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/73a6b0b1-d370-47e6-bda0-aa7d19c643b4', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'us-east-2', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'knn-2020-12-02-22-37-09-087', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-194-192.us-east-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/a36b6a50-fbe7-4983-b091-f406b04f2906', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-2:338648799047:training-job/knn-2020-12-02-22-37-09-087', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 INFO 140716057478976] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/73a6b0b1-d370-47e6-bda0-aa7d19c643b4', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/73a6b0b1-d370-47e6-bda0-aa7d19c643b4', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.194.192', 'AWS_REGION': 'us-east-2', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'knn-2020-12-02-22-37-09-087', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-194-192.us-east-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/a36b6a50-fbe7-4983-b091-f406b04f2906', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-2:338648799047:training-job/knn-2020-12-02-22-37-09-087', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 INFO 140716057478976] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 INFO 140716057478976] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/73a6b0b1-d370-47e6-bda0-aa7d19c643b4', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/73a6b0b1-d370-47e6-bda0-aa7d19c643b4', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'us-east-2', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'knn-2020-12-02-22-37-09-087', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-194-192.us-east-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/a36b6a50-fbe7-4983-b091-f406b04f2906', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-2:338648799047:training-job/knn-2020-12-02-22-37-09-087', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 INFO 140716057478976] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/73a6b0b1-d370-47e6-bda0-aa7d19c643b4', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/73a6b0b1-d370-47e6-bda0-aa7d19c643b4', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.194.192', 'AWS_REGION': 'us-east-2', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'knn-2020-12-02-22-37-09-087', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-194-192.us-east-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/a36b6a50-fbe7-4983-b091-f406b04f2906', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-2:338648799047:training-job/knn-2020-12-02-22-37-09-087', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 INFO 140716057478976] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/73a6b0b1-d370-47e6-bda0-aa7d19c643b4', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/73a6b0b1-d370-47e6-bda0-aa7d19c643b4', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.194.192', 'AWS_REGION': 'us-east-2', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'knn-2020-12-02-22-37-09-087', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'ip-10-0-194-192.us-east-2.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/a36b6a50-fbe7-4983-b091-f406b04f2906', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-2:338648799047:training-job/knn-2020-12-02-22-37-09-087', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 66 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 76 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:54 INFO 140716057478976] Using default worker.\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:55 INFO 140716057478976] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2020-12-02 22:39:55.252] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:55 INFO 140716057478976] nvidia-smi took: 0.0251557826996 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:55 INFO 140716057478976] Create Store: dist_async\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:55 ERROR 140716057478976] nvidia-smi: failed to run (127): /bin/sh: nvidia-smi: command not found\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:55 INFO 140716057478976] Using per-worker sample size = 200 (Available virtual memory = 30779023360 bytes, GPU free memory = 0 bytes, number of workers = 1). If an out-of-memory error occurs, choose a larger instance type, use dimension reduction, decrease sample_size, and/or decrease mini_batch_size.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1606948796.099057, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KNN\"}, \"StartTime\": 1606948796.099006}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-12-02 22:39:56.099] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 893, \"num_examples\": 1, \"num_bytes\": 1526540}\u001b[0m\n",
      "\u001b[34m[2020-12-02 22:39:56.159] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 59, \"num_examples\": 1, \"num_bytes\": 1526540}\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] push reservoir to kv... 1 num_workers 0 rank\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] ...done (200)\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 375, \"sum\": 375.0, \"min\": 375}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 375, \"sum\": 375.0, \"min\": 375}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 375, \"sum\": 375.0, \"min\": 375}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1606948796.165323, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KNN\", \"epoch\": 0}, \"StartTime\": 1606948796.099392}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] #throughput_metric: host=algo-1, train throughput=5678.47588515 records/second\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] pulled row count... worker 0 rows 200\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] pulled... worker 0 data (200, 3072) labels (200,) nans 0\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] calling index.train...\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] ...done calling index.train\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] calling index.add...\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] ...done calling index.add\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"model.serialize.time\": {\"count\": 1, \"max\": 2.6650428771972656, \"sum\": 2.6650428771972656, \"min\": 2.6650428771972656}, \"finalize.time\": {\"count\": 1, \"max\": 11.008977890014648, \"sum\": 11.008977890014648, \"min\": 11.008977890014648}, \"initialize.time\": {\"count\": 1, \"max\": 805.6390285491943, \"sum\": 805.6390285491943, \"min\": 805.6390285491943}, \"update.time\": {\"count\": 1, \"max\": 65.70982933044434, \"sum\": 65.70982933044434, \"min\": 65.70982933044434}}, \"EndTime\": 1606948796.179316, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KNN\"}, \"StartTime\": 1606948795.20564}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-12-02 22:39:56.228] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 975, \"num_examples\": 1, \"num_bytes\": 505120}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 125, \"sum\": 125.0, \"min\": 125}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 125, \"sum\": 125.0, \"min\": 125}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 125, \"sum\": 125.0, \"min\": 125}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1606948796.403026, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KNN\"}, \"StartTime\": 1606948796.179872}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] #test_score (algo-1) : ('accuracy', 0.032)\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] #test_score (algo-1) : ('macro_f_1.000', nan)\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] #quality_metric: host=algo-1, test accuracy <score>=0.032\u001b[0m\n",
      "\u001b[34m[12/02/2020 22:39:56 INFO 140716057478976] #quality_metric: host=algo-1, test macro_f_1.000 <score>=nan\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1574.9070644378662, \"sum\": 1574.9070644378662, \"min\": 1574.9070644378662}, \"setuptime\": {\"count\": 1, \"max\": 26.968955993652344, \"sum\": 26.968955993652344, \"min\": 26.968955993652344}}, \"EndTime\": 1606948796.408155, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KNN\"}, \"StartTime\": 1606948796.179396}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-12-02 22:40:05 Uploading - Uploading generated training model\n",
      "2020-12-02 22:40:05 Completed - Training job completed\n",
      "Training seconds: 61\n",
      "Billable seconds: 61\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    'feature_dim': 3072,\n",
    "    'k': 10,\n",
    "    'sample_size': 200,\n",
    "    'predictor_type': 'classifier' \n",
    "}\n",
    "output_path = 's3://' + bucket + '/' + prefix + '/default_example/output'\n",
    "knn_estimator = trained_estimator_from_hyperparams(s3_train_data, hyperparams, output_path, \n",
    "                                                   s3_test_data=s3_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the endpoint\n",
    "\n",
    "Now that we have a trained model, we are ready to run inference. The **knn_estimator** object above contains all the information we need for hosting the model. Below we provide a convenience function that given an estimator, sets up and endpoint that hosts the model. Other than the estimator object, we provide it with a name (string) for the estimator, and an **instance_type**. The **instance_type** is the machine type that will host the model. It is not restricted in any way by the parameter settings of the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_from_estimator(knn_estimator, estimator_name, instance_type, endpoint_name=None): \n",
    "    knn_predictor = knn_estimator.deploy(initial_instance_count=1, instance_type=instance_type,\n",
    "                                        endpoint_name=endpoint_name)\n",
    "    \n",
    "    knn_predictor.content_type = 'text/csv'\n",
    "    knn_predictor.serializer = csv_serializer\n",
    "    knn_predictor.deserializer = json_deserializer\n",
    "    return knn_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up the endpoint..\n",
      "-------------------------!"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "instance_type = 'ml.t2.medium'\n",
    "model_name = 'knn_%s'% instance_type\n",
    "endpoint_name = 'knn-ml-t2-medium-%s'% (str(time.time()).replace('.','-'))\n",
    "print('setting up the endpoint..')\n",
    "predictor = predictor_from_estimator(knn_estimator, model_name, instance_type, endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now that we have our predictor, let's use it on our test dataset. The following code runs on the test dataset, computes the accuracy and the average latency. It splits up the data into 100 batches, each of size roughly 500. Then, each batch is given to the inference service to obtain predictions. Once we have all predictions, we compute their accuracy given the true labels of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split into 1 batches, of size 125.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-46106da47782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mrun_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mnum_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Pass in one image?\n",
    "#client = boto3.client('sagemaker-runtime')\n",
    "                                     # Your endpoint name.\n",
    "#content_type = \"base64\"                                        # The MIME type of the input data in the request body.\n",
    "# accept = \"...\"                                              # The desired MIME type of the inference in the response.\n",
    "#payload = \"...\"   # Payload for inference.\n",
    "\n",
    "#response = client.invoke_endpoint(\n",
    "   # EndpointName=endpoint_name,\n",
    "    #ContentType=content_type,\n",
    "    #Body=b'bytes'|file\n",
    "\n",
    "#)\n",
    "\n",
    "#print(response);\n",
    "\n",
    "batches = np.array_split(test_features, 50)\n",
    "print('data split into 50 batches, of size %d.' % batches[0].shape[0])\n",
    "\n",
    "# obtain an np array with the predictions for the entire test set\n",
    "start_time = time.time()\n",
    "predictions = []\n",
    "for batch in batches:\n",
    "    #this is where we will pass in a single image from Kevin\n",
    "    result = predictor.predict(batch)\n",
    "    cur_predictions = np.array([result['predictions'][i]['predicted_label'] for i in range(len(result['predictions']))])\n",
    "    predictions.append(cur_predictions)\n",
    "predictions = np.concatenate(predictions)\n",
    "run_time = time.time() - start_time\n",
    "\n",
    "test_size = test_labels.shape[0]\n",
    "num_correct = sum(predictions == test_labels)\n",
    "accuracy = num_correct / float(test_size)\n",
    "print('time required for predicting %d data point: %.2f seconds' % (test_size, run_time))\n",
    "print('accuracy of model: %.1f%%' % (accuracy * 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(test_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
